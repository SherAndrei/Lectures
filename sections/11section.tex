\section{Введение в робастное оценивание}

Схема засорений Мартина-Йохаи имеет вид:
\[y_t = u_t + z^\gamma_t\xi_t,\ t = 1, \ldots, n\]
Здесь $\{u_t\}$ - "полезный сигнал" (временной ряд); \\
$\{z_t^\gamma\}$ - н.о.р. сл.в., $z_1^{\gamma} \sim Bin(1, \gamma)$
с $0 \leq \gamma\leq1$ ($\gamma$ - уровень засорения); \\
$\{\xi_t\}$ - н.о.р. сл.в. - грубые выбросы, $\xi_1$ - имеет распределение
$\mu_\xi\in M_\xi$;
Распределение $\mu_\xi$ неизвестно, а множество $M_\xi$ известно; \\
Последовательности $\{u_t\}, \{z^\gamma_t\}, \{\xi_t\}$ независимы между собой. \\
Пусть $y_1, \ldots, y_n$ - наблюдения, и распределение
вектора $Y_n=(y_1, \ldots, y_n)$ зависит от неизвестного параметра $\beta$.
Пусть $\hat{\beta}_n$ - некоторая оценка $\beta$

\underline{Основное предположение}

При любом $0 \leq \gamma\leq1$ существует предел
\[\hat{\beta}_n\xrightarrow{\P}\theta_\gamma,\ n\rightarrow\infty;\ \theta_0=\beta\]

\begin{definition}
    Если существует предел
    \[IF(\theta_\gamma, \mu_\xi)\defeq\lim_{\gamma\rightarrow+0}\frac{\theta_\gamma-\theta_0}{\gamma}\]
    то $IF(\theta_\gamma, \mu_\xi)$ называется \defin{функционалом влияния оценки $\widehat{\beta}_n$}
\end{definition}

Если функционал влияния существует, то 
\[\theta_\gamma = \theta_0 + IF(\theta_\gamma, \mu_\xi)\gamma + \littleO(\gamma),\ \gamma\rightarrow+0\]
\begin{leftbar}
    $IF(\theta_\gamma, \mu_\xi)$ характеризует главный линейный по
    $\gamma$ член в разложении по $\gamma$ асимптотического смещения $\theta_\gamma - \theta_0=\theta_\gamma-\beta$
\end{leftbar}

\begin{definition}
    Величина $GES(\theta_\gamma,M_\xi)\defeq\sup_{\mu_\xi\in M_\xi}\left\lvert IF(\theta_\gamma, \mu_\xi)\right\rvert$
    называется чувствительностью оценки $\widehat{\beta}_n$ к засорениям (выбросам).
\end{definition}
\begin{leftbar}
    Если $GES(\theta_\gamma,M_\xi)<\infty$, то главный член по $\gamma$
    асимптотического смещения $IF(\theta_\gamma,\mu_\xi)\gamma$
    равномерно по $\mu_\xi$ $\max$ при таких $\gamma$
\end{leftbar}
\begin{definition}
    Если $GES(\theta_\gamma,M_\xi)<\infty$, то оценка $\widehat{\beta}_n$
    называется \defin{робастной по смещению}, или $B$-робастной.
\end{definition}

\begin{example}[Выборочное среднее]
    \[\begin{cases}
        u_t = a + \eps_t \\
        y_t = u_t + z^\gamma_t\xi_t, \ t=1,\ldots,n
    \end{cases}\]
    $\{\eps_t\}$ - н.о.р. сл.в., $\E\eps_1=0$ (тогда $\E u_t=a$), $\E\vert\xi_1\vert<\infty$ \\
    Возьмем оценкой $a$ эмпирическое среднее $\overline{y}=\frac{1}{n}\sum_{t=1}^ny_t$.
    Тогда $\overline{y}\xrightarrow{\P}E(u_1+z_1^\gamma\xi_1)=a+\gamma\E\xi_1=\theta^{LS}_\gamma$
    Функция $\theta_\gamma^{LS}$ определена при всех $\gamma$,
    \[\frac{d\theta_\gamma^{LS}}{d\gamma}=\E\xi_1=IF(\theta_\gamma^{LS}, \mu_\xi)\]
    Если $M_1$ - класс распределений с конечным первым моментом, то
    \[GES(\theta_\gamma^{LS}, M_1) = \sup_{\mu_\xi\in M_1} \vert\E\xi_1\vert = \infty\]
    Оценка $\overline{y}$ \underline{не $B$-робастна} на  классе $M_1$!
\end{example}
\begin{example}[Выборочная медиана]
    Пусть
    \begin{equation} \label{def::var_series}
        u_t=a+\eps_t,\ t=1,\ldots,n,\text{ где }\{\eps_t\}\text{ - н.о.р. сл.в.}
    \end{equation} 
    $\eps_1\sim G(x)$, функция распределения $G(x)$ неизвестна,
    $G(0)=1/2$. Тогда функция распределения $u_1$ есть $F(x)=G(x-a)$,
    то есть $F(a)=1/2$. Таким образом, медиана $G(x)$ это 0, медиана $F(x)$ - $a$.
    \begin{leftbar}
        Если $\eps_1$ имеет симметричное относительно 0 распределение
        (то есть $\eps_1\overset{d}{=}-\eps_1$, что для непрерывной
        $G(x)$ равносильно условию $G(x)+G(-x)=1\ \forall x$), то
        автоматически $G(0)=1/2$. Если вдобавок $\E\lvert\eps_1\rvert<\infty$,
        то $\E\eps_1=0,\E u_1=a$
    \end{leftbar}
    Итак, при сформулированных условия оценку медианы можно использовать
    как оценку математического ожидания.

    Пусть $u_{(1)}\leq u_{(2)}\leq\ldots\leq u_{(n)}$ будет вариационный
    ряд наблюдений $u_1,\ldots,u_n$.
    \begin{definition}
        Величина
        \[
            \widehat{m}_n=\begin{cases}
                u_{(k+1)}\ &n=2k-1 \\
                \frac{u_{(k+1)} + u_{(k)}}{2}\ &n=2k
            \end{cases}
        \]
        называется \defin{выборочной медианой} наблюдений $u_1,\ldots,u_n$.
    \end{definition}

    Мы знаем, что если $G(x)$ дифф. в нуле, и $g(0) = G'(0)>0$,
    то для выборочной медианы справедлива асимптотическая нормальность:
    \[ \sqrt{n}(\widehat{m}_n - a)\xrightarrow{d}N(0, \frac{1}{4g^2(0)}),\ n\rightarrow\infty\]
    Если в \eqref{def::var_series} $\{\eps_t\}$ - н.о.р., $\E\eps_1=0$,
    $0<\E\eps_1^2=\sigma^2<\infty$, то $\sqrt{n}(\widetilde{u}-a)\xrightarrow{d}N(0,\sigma^2)$.
    Значит асимптотическая оптимальная эффективность выборочной медианы относительно $\widetilde{u}$
    равна
    \[\boxed{e_{\widehat{m}_n,\ \overline{X}}=4g^2(0)\sigma^2}\]

    \underline{Изучим $B$-робастность выборочной медианы.}
    Пусть
    \[
    \begin{array}{cc}
    \begin{cases}
        u_t=a+\eps_t \\
        y_t=u_t+z_t^\gamma\xi_t,\ t=1,\ldots,n
    \end{cases} &
    \widehat{m}_n^y=
    \begin{cases}
        y_{(k+1)},\ n=2k-1 \\
        \frac{y_{(k)}+y_{(k+1)}}{2},\ n=2k
    \end{cases} \\
    \end{array}
    \]
    \begin{theorem}
        Пусть $\exists\ g(x)=G'(x)$, $g(x)$ непрерывна и ограничена, $g(0)>0,\ G(0)=1/2$. Тогда:
        \begin{enumerate}
            \item $\widehat{m}_n^y\xrightarrow{\P}\theta_\gamma^m,\ \theta_0=a$
            \item Существует функционал влияния выборочной медианы
            \[IF(\theta_\gamma^m,\mu_\xi)=\frac{1-2\E G(-\xi_1)}{2g(0)}\]
            \item Чувствительность выборочной медианы на классе всех возможных
            распределений $M_\xi$
            \[GES(\theta_\gamma^m,\mu_\xi)=\sum_{\mu_\xi\in M_\xi}\lvert IF(\theta_\gamma^m,\mu_\xi)\rvert=\frac{1}{2g(0)}<\infty\]
            то есть \underline{выборочная медиана $B$-робастна}.
        \end{enumerate}
    \end{theorem}
    \begin{proof}
        \begin{enumerate}
            \item Выборочная медиана $\widehat{m}_n^y$ 
            удовлетворяет уравнению
            \begin{equation} \label{def::sample_median}
                l_n(\theta)\defeq\frac{1}{n}\sum_{t=1}^nsgn(y_t-\theta)=0,\text{ где }sgn(x)=\begin{cases}
                    -1, x<0 \\
                    0, x=0 \\
                    1, x>0
                \end{cases}
            \end{equation}
            Справедливость формулы \eqref{def::sample_median} легко понять из следующих рисунков:
            % TODO
            \ifdraft
                \begin{figure}[h!]
                    \centering
                    \begin{gnuplot}[scale=0.6]
                        set xlabel '$n=1$'
                        set border 0
                        set xzeroaxis
                        set yzeroaxis
                        set xrange [-0.2:3]
                        set yrange [-1.5:1.5]
                        set ytics (0, 1, -1)
                        unset xtics
    
                        set arrow from -0.2,1 to 1,1
                        set arrow from 3,-1 to 1,-1
    
                        set label at 1,0 "$y_{(1)}$" point pointtype 7 pointsize 2 offset -1,-1.3
    
                        set label at 2,1 "$\\widehat{m}_1^y$"
                        set arrow from 1.9,0.9 to 1.1,0.1
    
                        plot 0 notitle
                    \end{gnuplot}
                    \begin{gnuplot}[terminal=epslatex,scale=0.6]
                        set xlabel '$n=2$'
                        set border 0
                        set xzeroaxis ls -1
                        set yzeroaxis ls -1
                        set xrange [-0.2:3]
                        set yrange [-2.5:2.5]
                        set ytics (0, 1, -1, 2, -2)
                        unset xtics
    
                        set arrow from -0.2,2 to 1,2
                        set arrow from 3,-2 to 2,-2
                        set arrow from 1,0 to 2,0 heads
    
                        set label at 1,1 "" point pointtype 7 pointsize 1
                        set label at 2,-1 "" point pointtype 7 pointsize 1
    
                        set label at 1,0 "$y_{(1)}$" offset -1,-1.3
                        set label at 2,0 "$y_{(2)}$" offset -1,-1.3
    
                        set label at 2,1 "$\\widehat{m}_2^y$"
                        set arrow from 1.96,0.9 to 1.6,0.1
                        set label at 1.5,0 "X"
    
                        plot 0 notitle ls -1
                    \end{gnuplot}
                \end{figure}
            \fi

            Так бывает всегда: при нечетном $n$ решение уравнения \eqref{def::sample_median}
            всегда $\exists!$, это $\widehat{m}_n^y$; при четном $n$ решений целый
            интервал и $\widehat{m}_n^y$ - его середина.

            В силу Закона Больших Чисел при любом $\theta$ и любом $0\leq\gamma\leq1$
            \[ l_n(\theta)=\frac{1}{n}\sum_{t=1}^nsgn(y_t-\theta)\xrightarrow{\P}\E sgn(y_1-\theta)\defeq\Lambda_M(\gamma,\theta) \]
            
            \underline{Задача:} Пусть $\xi$ и $\eta$ - независимые случайные векторы, причем
            $\eta$ - дискретный вектор со значениями $\eta_1,\eta_2,\ldots$. Проверить, что
            \[\E \phi(\xi,\eta)=\sum_{k\geq1}\E\phi(\xi,\eta_k)\P(\eta=\eta_k)=\sum_{k\geq1}\E(\phi(\xi,\eta_k)\vert H_k)\P(H_k),\text{ где гипотеза } H_k=(\eta=\eta_k) \]

            Найдем удобный вид для $\Lambda_M(\gamma,\theta)$. Имеем
            \begin{equation} \label{eq::lambda_transforming}
                \Lambda_M(\gamma,\theta)=\E(1-2I(y_1-\theta\leq0))=1-2\E I(\eps_1\leq\theta-a-z_1^\gamma\xi_1)=
                1-2\E G(\theta-a-z_1^\gamma\xi_1)
            \end{equation}
            так как $signx=1-2I(x<0),\ x\neq0$. Чтобы упростить \eqref{eq::lambda_transforming},
            введем две гипотезы $H_1=(z_1^\gamma=0)$ и $H_2=(z_2^\gamma=1)$.
            Тогда, используя задачу, получаем из \eqref{eq::lambda_transforming}:
            \[\Lambda_M(\gamma,\theta)=1-2(1-\gamma)G(\theta-a)-2\gamma\E G(\theta-a-\xi_1)\]
            Функция $\Lambda_M(\gamma,\theta)$ определена при всех $\gamma,\theta$.
            \item Функция $\Lambda_M(\gamma,\theta)$ в окрестности точки $(0,a)$ удовлетворяет
            всем предположениям теормы о неявной функции. А именно:
            \begin{enumerate}
                \item $\Lambda_M(0,a)=1-2G(0)=0$
                \item Существует и непрерывны по паре $(\gamma,\theta)$ функции
                $\frac{\partial\Lambda_M(\gamma,\theta)}{\partial\gamma}$ и $\frac{\partial\Lambda_M(\gamma,\theta)}{\partial\theta}$ 
                \item $$\frac{\partial\Lambda_M(\gamma,\theta)}{\partial\theta}=-2g(0)\neq0$$
            \end{enumerate}
            Значит, в окрестности точки $(0,a)$ определена функция $\theta_m(\gamma)=\theta_\gamma^m$ такая, что
            \[\Lambda_M(\gamma,\theta_\gamma^m)=0\]
            Кроме того, $\theta_0^m=a;\ \theta_\gamma^m\rightarrow\theta_0$ при $\gamma\rightarrow0$;
            Функция $\theta_0^m$ дифференцируема в точке $\gamma=0$, и
            \begin{equation} \label{eq::theta_func_derivative}
                \left.\frac{d\theta_\gamma^m}{d\gamma}\right\rvert_{\gamma=0}=-\left(\frac{\partial\Lambda_m(0,a)}{\partial\theta}\right)^{-1}\frac{\partial\Lambda_m(0,a)}{\partial\gamma}=\frac{1-2\E G(-\xi_1)}{2g(0)}
            \end{equation}
            \item Покажем, что
            \begin{equation} \label{eq::sample_median_p_conv}
                \widehat{m}_n^y\xrightarrow{\P}\theta_\gamma^m,\ n\rightarrow\infty
            \end{equation}
            Тогда из \eqref{eq::theta_func_derivative}-\eqref{eq::sample_median_p_conv}
            будет слеовать, что функционал влияния выборочной медианы равен
            \begin{equation}\label{eq::theta_influence_func}
                IF(\theta_\gamma^m,\mu_\xi)=\frac{1-2\E G(-\xi_1)}{2g(0)}
            \end{equation}
            Модуль числителя в \eqref{eq::theta_influence_func} не больше единицы, причем
            если $\theta_1$ неслучайно и $\theta_1\rightarrow\infty$,
            то числитель стремится к единице. Значит,
            \[GES(\theta_\gamma^m,M_\xi)=\sup_{\mu_\xi\in M_\xi}\lvert IF(\theta_\gamma^M,\mu_\xi)\rvert=\frac{1}{2g(0)}\]
            то есть мы докажем теорему.

            Докажем \eqref{eq::sample_median_p_conv}. Имеем при малых $\gamma,\ \xi,\ \theta$ ($\gamma$-фикс.) вблизи $a$:
            \[\frac{\partial\Lambda_M(\gamma,\theta)}{\partial\theta}=-2(1-\gamma)g(\theta-a)-2\gamma\E g(\theta-a-\xi_1)<0\]
            то есть \underline{$\Lambda_M(\gamma,\theta)$ убывает по $\theta$}.
            Значит, $\begin{cases}
                \Lambda_M(\gamma,\theta_\gamma^m-\Delta)>0\\
                \Lambda_M(\gamma,\theta_\gamma^m+\Delta)<0
            \end{cases}$
            % TODO
            \ifdraft
                \begin{figure}[h]
                    \centering 
                    \begin{gnuplot}[terminal=epslatex, scale=0.6]
                        set xlabel '$\theta$'
                        set border 0
                        set xrange [-1:4]
                        set yrange [-0.6:0.6]
                        set xzeroaxis ls -1
                        set yzeroaxis ls -1
                        unset ytics
                        unset xtics
                        
                        f(x) = (-0.4*x+1.6)**(3)-0.5
                        a = 1
                        b = 3
                        f_cropped(x) = (x >= a && x <= b) ? f(x) : 1/0
    
                        set arrow from a,0 to a,f(a) nohead dashtype 3
                        set arrow from b,0 to b,f(b) nohead dashtype 3
    
                        set label "$\\theta_\\gamma^m$" at 2.016,0 point pointtype 7 pointsize 1 offset -1,-1.3
                        set label "$\\theta_\\gamma^m-\\Delta$" at a,0 point pointtype 7 pointsize 1 offset 0,-1
                        set label "$\\theta_\\gamma^m+\\Delta$" at b,0 point pointtype 7 pointsize 1 offset 0,1
                        set label "0" at 0,0 offset -2,-1
                        plot f_cropped(x)  title '$\Lambda_M(\gamma,\theta_\gamma^m-\Delta)$'
                    \end{gnuplot}
                \end{figure}
            \fi
            Но 
            \begin{equation} \label{eq::sample_plaus_func_ineq}
                \begin{cases}
                    l_n(\theta_\gamma^m-\Delta)\xrightarrow{\P}\Lambda_M(\gamma,\theta_\gamma^m-\Delta)>0 \\
                    l_n(\theta_\gamma^m+\Delta)\xrightarrow{\P}\Lambda_M(\gamma,\theta_\gamma^m+\Delta)<0
                \end{cases}
            \end{equation}
            Функция $l_n(\theta)$ монотонно убывает (точнее, не возрастает) по $\theta$.
            В силу \eqref{eq::sample_plaus_func_ineq} с вероятностью сколь угодно близкой к
            единице при достаточно больших $n$ \underline{все} корни уравнения $l_n(\theta)=0$
            лежат в интервале $(\theta_\gamma^m-\Delta, \theta_\gamma^m+\Delta)$. А значит
            и выборочная медиана тоже! Поскольку $\Delta>0$ любое, то получаем
            \begin{equation*}
                \widehat{m}_n^y\xrightarrow{\P}\theta_\gamma^m,\ n\rightarrow\infty
            \end{equation*}
            что и доказывает теорему.
        \end{enumerate}
    \end{proof}
\end{example}

\subsubsection*{Как находить функционал влияния в общей ситуации?}
Пусть оценка $\widehat{\beta}_n$ ищется как корень уравнения:
\begin{equation}\label{eq::beta_estimate}
    l_n(\theta)\defeq \frac{1}{n}\sum_{t=1}^n\phi_t(J_n, \theta)=0
\end{equation}
Пусть будут выполнены следующие условия
\begin{enumerate}
    \item \[l_n(\theta)=\frac{1}{n}\sum_{t=1}^n\phi_t(J_n,\theta)\xrightarrow{\P}\Lambda(\gamma,\theta)\]
        при всех $\lvert\theta-\beta\rvert<\delta,\ 0\leq\gamma<\gamma_0$
    \item $\Lambda(0,\beta)=0$
    \item Пусть $\Lambda(\gamma,\theta)$ можно продолжить на отрезок малых $\gamma$ так,
    что при $\lvert\theta-\beta\rvert<\delta,\ \lvert\gamma\rvert<\gamma_0$ сущесвтуют
    и непрерывны по паре аргументов $(\gamma,\theta)$ частные производные
    $\frac{\partial\Lambda(\gamma,\theta)}{\partial\gamma}$, $\frac{\partial\Lambda(\gamma,\theta)}{\partial\theta}$.
    \item Пусть $\lambda(\beta)\defeq\frac{\partial\Lambda(0,\theta)}{\partial\theta}\neq0$
\end{enumerate}
\begin{theorem} \label{th::M_estimate_sample_median}
    Пусть выполнены условия (1)-(4), и функции $\phi_t(J_n,\theta)$ непрерывны по $\theta$.
    Тогда уравнение \eqref{eq::beta_estimate} с вероятностью, стремящейся к единице при $n\rightarrow\infty$,
    имеет при достаточно малых $\gamma>0$ решение $\widehat{\beta}_n$, что соответствующая
    оценка $\widetilde{\beta}_n\xrightarrow{\P}\theta_\gamma,\ \theta_0=0$, и существует
    функционал влияния:
    \[\boxed{IF(\theta_\gamma,\mu_\xi)=-\frac{1}{\lambda(\beta)}\frac{\partial}{\partial\gamma}\Lambda(0,\beta)}\]
\end{theorem}
\begin{example}[$M$-оценка медианы]
    Пусть 
    \[\begin{cases}
        u_t=a+\eps_t \\ y_t=u_t+z_t^\gamma\xi_t
    \end{cases} \{\eps_t\}\text{-н.о.р.},\ \eps_1\sim g(x)=G'(x),\ g(x)=g(-x)\]
     Тогда $a$ - медиана функции распределения случайной величины $u_1$.

     Будем искать оценку $a$, обозначим ее как $\widehat{a}_n$, как корень уравнения
     \begin{equation}\label{eq::a_estimate}
         \sum_{t=1}^n\psi(y_t-\theta)=0
     \end{equation}
     Тогда оценка называется \defin{$M$-оценкой}. В частности, при $\psi(x)=x,\ \widehat{a}_n=\overline{y}$;
     при $\psi(x)=sgn(x),\ \widehat{a}_n=\widehat{m}_n^y$.

     Пусть выполняются условия: \begin{enumerate}
         \item $\psi(x)$ - нечетная строго возрастающая фунцкия
         \[\lim_{x\rightarrow+\infty}\psi(x)=c_1>0,\ \lim_{x\rightarrow-\infty}\psi(x)=c_2<\infty\]
         \item Существует непрерывная и ограниченая $\psi'(x)$, $\E\psi'(\eps_1)\neq0$
     \end{enumerate}
     Тогда уравнение \eqref{eq::a_estimate} всегда имеет и притом \underline{единственное} решение.
     Условия (1)-(2) выполнены, например, для $\psi(x)=arctan(x)$.

     Найдем функционал влияния и чувствительность $M$-оценки, используя теорему \ref{th::M_estimate_sample_median}.
     Проверим ее условия:
     \begin{enumerate}
         \item 
         \[\frac{1}{n}\sum_{t=1}^n\psi(y_t-\theta)\xrightarrow{\P}\E\psi(y_1-\theta)\defeq\Lambda(\gamma,\theta),\ \forall\theta,\ \forall0\leq\gamma\leq1\]
         Введем гипотезы $H_1=(z_1^\gamma=0),\ H_2=(z_2^\gamma=0)$. Тогда 
         \[\Lambda(\gamma,\theta)=\sum_{i=1}^2\E(\psi(\underbrace{\eps_1+a+z_1^\gamma\xi_1}_{y_1}-\theta)\vert H_i)\P(H_i)
         =(1-\gamma)\E\psi(\eps_1+a-\theta)+\gamma\E\psi(\eps_1+\xi_1+a-\theta)\]
         \item $\Lambda(0,a)=\E\psi(\eps_1)=0$, так как $\psi(x)$ - нечетная, а $g(x)$-четная.
         \item Функция $\Lambda(\gamma,\theta)$ определена при всех $\gamma$ и $\theta$.
         Частные производные $\frac{\partial\Lambda(\gamma,\theta)}{\partial\gamma}$, $\frac{\partial\Lambda(\gamma,\theta)}{\partial\theta}$
         существуют при условиях (1)-(2) и непрерывны по паре $(\gamma,\theta)$. В частности,
         \[\frac{\partial\Lambda(0,a)}{\partial\gamma}=-\E\psi(\eps_1)+\E\psi(\eps_1+\xi_1)=\E\psi(\eps_1+\xi_1)\]
         \item $\frac{\partial\Lambda(0,a)}{\partial\theta}=-\E\psi'(\eps_1)\neq0$
     \end{enumerate}
     В силу теоремы \ref{th::M_estimate_sample_median} 
    \[\widehat{a}_n\xrightarrow{\P}\theta_\gamma,\ \theta_0=a \]
    \[IF(\theta_\gamma,\mu_\xi)=\frac{\E\psi(\eps_1+\xi_1)}{\E\psi'(\eps_1)} \]
    \[GES(\theta_\gamma, M_\xi)\leq\frac{\max\{|c_1|,|c_2|\}}{\E\psi'(\eps_1)}<\infty,\text{ $M_\xi$-класс всех вер. распределений}\]
\end{example}
